

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Lab 1- Information theory &#8212; Biologically Intelligent eXploration (BIX)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/lab1-information';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Lab 2 - Introduction to explorationlib" href="lab2-explorelib.html" />
    <link rel="prev" title="Introduction to python" href="intro-python.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/levy-flight.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/levy-flight.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Biologically Intelligent eXploration (BIX)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro-python.html">Introduction to python</a></li>

<li class="toctree-l1 current active"><a class="current reference internal" href="#">Lab 1- Information theory</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab2-explorelib.html">Lab 2 - Introduction to <em>explorationlib</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="lab3-chemotaxis.html">Lab 3 - Chemotaxis</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab4-evidence_accumulation.html">Lab 4 - Evidence Accumulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab5-cbgt.html">Lab 5 - CBGT decision-making simulations</a></li>

<li class="toctree-l1"><a class="reference internal" href="lab7-foraging.html">Lab 7 - Biologically intelligent foraging</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Exercises</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../exercises/getting-started.html"><strong>Exercise 1: Github &amp; Colab</strong></a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/CoAxLab/BIX-book/main?urlpath=tree/book/notebooks/lab1-information.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/CoAxLab/BIX-book/blob/main/book/notebooks/lab1-information.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/lab1-information.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lab 1- Information theory</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background">Background</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-entropy-again"><strong>What is entropy again?</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-between-variables"><strong>Entropy between variables</strong>.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mutual-information-between-variables"><strong>Mutual information between variables</strong>.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-entropy-between-variables"><strong>Transfer entropy between variables</strong>.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-setup">Section - Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-1-entropy">Section 1 - Entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-our-two-neurons">Visualizing our two neurons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-1-1">Question 1.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-1-2">Question 1.2</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-2-mutual-information">Section 2 - Mutual information</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-2-1">Question 2.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-2-2">Question 2.2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-2-3">Question 2.3</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-3-transfer-entropy">Section 3 - Transfer entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-3-1">Question 3.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-3-2">Question 3.2</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lab-1-information-theory">
<h1>Lab 1- Information theory<a class="headerlink" href="#lab-1-information-theory" title="Permalink to this heading">#</a></h1>
<p>This lab has a few goals designed to get you comfortable with working with python and playing with the basiscs of information theory.</p>
<p>Sections:</p>
<ol class="arabic simple">
<li><p>Entropy</p></li>
<li><p>Mutual information</p></li>
<li><p>Transfer entropy</p></li>
</ol>
<section id="background">
<h2>Background<a class="headerlink" href="#background" title="Permalink to this heading">#</a></h2>
<p>We are going to assume a basic familiarity with python. If you need an introduction, see the introduction notebook at the beginning of this book. That should get you enough familiarity to get started.</p>
<p>For this lab we won’t be working with our main library, <em>explorationlib</em>. We’ll use a few standard libraries to both get more comfortable with python and to refresh the concepts of information theory discussed in class.</p>
<section id="what-is-entropy-again">
<h3><strong>What is entropy again?</strong><a class="headerlink" href="#what-is-entropy-again" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>According to Shannon’s definition, the entropy <span class="math notranslate nohighlight">\(H(X)\)</span> of a discrete random variable is: <span class="math notranslate nohighlight">\(H(X)= \sum_{x \in X} p(x) \log _2 p(x)^{-1}\)</span>.</p></li>
<li><p>Here we are assuming that the discrete variable is binary, hence the use of <span class="math notranslate nohighlight">\(\log _2\)</span></p></li>
<li><p>A key aspect of the definition entropy is the ‘surprise’ termn, <span class="math notranslate nohighlight">\(p(x)^{-1}\)</span>. The more surprising an outcome is, the more valuable that bit of information is. We will return to this later in class.</p></li>
</ul>
</section>
<section id="entropy-between-variables">
<h3><strong>Entropy between variables</strong>.<a class="headerlink" href="#entropy-between-variables" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The <em>joint entropy</em> between two discrete random variables, <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, is just an expansion of the regular concept of entropy: <span class="math notranslate nohighlight">\(H(X, Y)= \sum_{x \in X} p(x,y) \log _2 p(x,y)^{-1}\)</span>.</p></li>
<li><p>Note that in here, <span class="math notranslate nohighlight">\(p(x,y)\)</span> is the joint probability distribution between the variables.</p></li>
<li><p>The joint information is always symmetircal, i.e., <span class="math notranslate nohighlight">\(H(X,Y) = H(Y,X)\)</span>.</p></li>
<li><p>Expanding out from the rules of conditional probabilities (thank you Mr. Bayes), the joint entropy can be expanded as the product of the entropy of the primary variable and the conditional entropy of the two variables: <span class="math notranslate nohighlight">\(H(X,Y) = H(X) + H(Y|X)\)</span>. <em>Pay attention to the ordering of terms, it gets important later</em>.</p></li>
</ul>
</section>
<section id="mutual-information-between-variables">
<h3><strong>Mutual information between variables</strong>.<a class="headerlink" href="#mutual-information-between-variables" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Sticking with the idea of joint entropy, the <em>conditional entropy</em> <span class="math notranslate nohighlight">\(H(X|Y)\)</span> reflects the residual entropy of <span class="math notranslate nohighlight">\(X\)</span> after you have knowledge about <span class="math notranslate nohighlight">\(Y\)</span>. This is expressed as: <span class="math notranslate nohighlight">\(H(X|Y)=H(X)-I(X;Y)\)</span>.</p></li>
<li><p>We call this second term, <span class="math notranslate nohighlight">\(I(X;Y)\)</span> the <em>mutual information</em> between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. It is the information provided by Y about X. If you were in statistics and working with continuous variables, this would be the correlation (or covariance).</p></li>
<li><p>We can rewrite the equation above as <span class="math notranslate nohighlight">\(I(X;Y) = H(X) - H(X|Y) = \sum_{x \in X, y \in Y} p(x,y) \log _2 \frac{p(x,y)}{p(x)p(y)}\)</span></p></li>
</ul>
</section>
<section id="transfer-entropy-between-variables">
<h3><strong>Transfer entropy between variables</strong>.<a class="headerlink" href="#transfer-entropy-between-variables" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>In statistics (including information theory), causality follows Humeian logic: cause temporally preceeds effect. Thus, the term ‘causality’ in a statistical sense really just looks at the asymmetry in cross-correlations between two or more time series.</p></li>
<li><p>Information theory relies on <em>transfer entropy</em> <span class="math notranslate nohighlight">\(T(X \rightarrow Y)\)</span> to estimate this statistical relationship.</p></li>
<li><p>Trasfer entropy captures how much information the source has transfered to the receiver: <span class="math notranslate nohighlight">\(T(X \rightarrow Y) = I(Y_{f} ; X_p | Y_p) = H(Y_f|Y_p) - H(Y_f|X_p, Y_p)\)</span>, which can be rewritten as <span class="math notranslate nohighlight">\(T(X \rightarrow Y) =  \sum_{y_f \in Y_f, x_p \in X_p, y_p \in Y_p} p(y_f,x_p,y_p) \log _2 \frac{p(y_f,x_p|y_p)}{p(y_f|y_p)p(x_p|y_p)}\)</span></p></li>
</ul>
</section>
</section>
<section id="section-setup">
<h2>Section - Setup<a class="headerlink" href="#section-setup" title="Permalink to this heading">#</a></h2>
<p>Use the rocket-shaped button to open this assignment in a colab. Once it is open, if it is open, run all the cells. Read each cell, then run it, that is. It’s that simple.</p>
<p>We will discuss a different way to work with notebooks for the Exercises, but for now just load in Colab.</p>
<p>For this lab we’ll load some standard libraries for working with mutual information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import the general libraries we will be using</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="section-1-entropy">
<h2>Section 1 - Entropy<a class="headerlink" href="#section-1-entropy" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>For this section we will simulate two cells, a presynaptic and postsynaptic cell. The data will consist of spikes. We will vary the degree of dependency between the neurons and look at their relative entropies.</p></li>
<li><p>One way to achieve this is to use a Poisson process to simulate the neurons. Here, the firing of each neuron at each time step is modeled as a binary event that occurs with some probability. The influence of the first neuron on the second is represented by increasing the firing probability of the second neuron when the first one fires.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Time and rates</span>
<span class="n">total_time_sec</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">sampling_rate_hz</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="n">total_time_sec</span> <span class="o">*</span> <span class="n">sampling_rate_hz</span>

<span class="c1"># Probabilities</span>
<span class="n">base_firing_prob</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">influence</span> <span class="o">=</span> <span class="mf">0.03</span>
<span class="n">noise_level</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="k">def</span> <span class="nf">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="n">influence</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">,</span> <span class="n">neuron1</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simulate the spiking of a neuron.</span>

<span class="sd">    If neuron1 is not None, then this neuron is influenced by neuron1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">spikes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="n">firing_prob</span> <span class="o">=</span> <span class="n">base_firing_prob</span>
        
        <span class="k">if</span> <span class="n">neuron1</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">neuron1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">firing_prob</span> <span class="o">+=</span> <span class="n">influence</span>
            
        <span class="n">firing_prob</span> <span class="o">+=</span> <span class="n">noise_level</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">firing_prob</span><span class="p">:</span>
            <span class="n">spikes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
            
    <span class="k">return</span> <span class="n">spikes</span>

<span class="c1"># Simulate the two neurons</span>
<span class="n">neuron1</span> <span class="o">=</span> <span class="n">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">)</span>
<span class="n">neuron2</span> <span class="o">=</span> <span class="n">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="n">influence</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">,</span> <span class="n">neuron1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Neuron 1 spike train:&quot;</span><span class="p">,</span> <span class="n">neuron1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Neuron 2 spike train:&quot;</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>What we have created are two binary vectors, <em>neuron1</em> and <em>neuron2</em>, that represent the spike trains of two neurons over 5 seconds at a 1 kHz sampling rate.</p>
<p>Each time step is a binary event where 1 represents a spike and 0 represents no spike. The base firing probability is 2%, but this is modified by two factors: the influence of the first neuron on the second, and some independent noise.</p>
<p>The <em>influence</em> parameter controls how much the first neuron affects the second: whenever the first neuron fires, the firing probability of the second neuron is increased by the influence factor. The <em>noise level</em> parameter controls the amount of independent noise in the firing probabilities. This noise is modeled as Gaussian noise and is independent for each neuron and each time step.</p>
<section id="visualizing-our-two-neurons">
<h3>Visualizing our two neurons<a class="headerlink" href="#visualizing-our-two-neurons" title="Permalink to this heading">#</a></h3>
<p>We can use a raster plot to visualize the spike times of our neurons. For this we will use matplotlib.</p>
<p>In a raster plot, each row corresponds to a different repetition of the experiment (a different neuron in this case), and the x-axis represents time. Each small vertical line (marker) represents a spike.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_spikes</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">,</span> <span class="n">sampling_rate_hz</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Plot the spikes of the two neurons as a raster plot.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">time_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">neuron1</span><span class="p">))</span> <span class="o">/</span> <span class="n">sampling_rate_hz</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="c1"># Neuron 1</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">eventplot</span><span class="p">(</span><span class="n">time_points</span><span class="p">[</span><span class="n">neuron1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Neuron 1&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Spikes&quot;</span><span class="p">)</span>

    <span class="c1"># Neuron 2</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">eventplot</span><span class="p">(</span><span class="n">time_points</span><span class="p">[</span><span class="n">neuron2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Neuron 2&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Spikes&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time (sec)&quot;</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Run the plotting function</span>
<span class="n">plot_spikes</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">,</span> <span class="n">sampling_rate_hz</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now calculate the entropy of each neuron. For this we will use a simple function that follows the equations for entropy in the Background and the reading.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_entropy</span><span class="p">(</span><span class="n">neuron</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the entropy of the spike train of a neuron.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Calculate the probabilities of 0 and 1</span>
    <span class="n">p_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">neuron</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">neuron</span><span class="p">)</span>
    <span class="n">p_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">neuron</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">neuron</span><span class="p">)</span>

    <span class="c1"># Use the formula for entropy of a binary variable</span>
    <span class="c1"># Note: When p_0 or p_1 is 0, their contribution to the entropy is 0</span>
    <span class="n">entropy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">p_0</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">entropy</span> <span class="o">-=</span> <span class="n">p_0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p_1</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">entropy</span> <span class="o">-=</span> <span class="n">p_1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">entropy</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s see how our neurons are doing.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate and print the entropies</span>
<span class="n">entropy_neuron1</span> <span class="o">=</span> <span class="n">calculate_entropy</span><span class="p">(</span><span class="n">neuron1</span><span class="p">)</span>
<span class="n">entropy_neuron2</span> <span class="o">=</span> <span class="n">calculate_entropy</span><span class="p">(</span><span class="n">neuron2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Entropy of Neuron 1: </span><span class="si">{</span><span class="n">entropy_neuron1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Entropy of Neuron 2: </span><span class="si">{</span><span class="n">entropy_neuron2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="question-1-1">
<h3>Question 1.1<a class="headerlink" href="#question-1-1" title="Permalink to this heading">#</a></h3>
<p>Increase the baseline firing rate parameter, <em>base_firing_prob</em>, by a factor of 10 to 0.2. What happens to the entropies of the neurons? Explain why this effect may or may not occur.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your answer here as a comment. Explain yourself.</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="question-1-2">
<h3>Question 1.2<a class="headerlink" href="#question-1-2" title="Permalink to this heading">#</a></h3>
<p>Put the baseline firing rate parameter back to 0.02. Increase the influence parameter, from neuron 1 to neuron 2, by a factor of 10 to 0.3. What happens to the entropies of the neurons? Explain why this effect may or may not occur.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your answer here as a comment. Explain yourself.</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="section-2-mutual-information">
<h2>Section 2 - Mutual information<a class="headerlink" href="#section-2-mutual-information" title="Permalink to this heading">#</a></h2>
<p>We have our two happy little neurons firing. We’ve played with the parameters to see how it impacts their relative entropy. Now let’s go back to the original parameter settings and see about estimating the mutual information between our neurons.</p>
<p>Recall that to estimate the mutual information, we need to estimate the conditional entropy for <span class="math notranslate nohighlight">\(X\)</span> on <span class="math notranslate nohighlight">\(Y\)</span>. For binary variables things are a bit easier because <span class="math notranslate nohighlight">\(H(X|Y) = H(Y) - H(X,Y)\)</span>. Which means we only need to get both independnet entropies and the joint entropy. This leaves us with this simple and beautiful equation: <span class="math notranslate nohighlight">\(I(X; Y) = H(X) + H(Y) - H(X, Y)\)</span>.</p>
<p>We can easily write a function to do this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_joint_entropy</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the joint entropy of the spike trains of two neurons.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Calculate the probabilities of each combination of 0 and 1</span>
    <span class="n">p_00</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">neuron1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">neuron2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">neuron1</span><span class="p">)</span>
    <span class="n">p_01</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">neuron1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">neuron2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">neuron1</span><span class="p">)</span>
    <span class="n">p_10</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">neuron1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">neuron2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">neuron1</span><span class="p">)</span>
    <span class="n">p_11</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">neuron1</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">neuron2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">neuron1</span><span class="p">)</span>

    <span class="c1"># Use the formula for entropy of a binary variable</span>
    <span class="c1"># Note: When p_ij is 0, its contribution to the entropy is 0</span>
    <span class="n">joint_entropy</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">p_00</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">joint_entropy</span> <span class="o">-=</span> <span class="n">p_00</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_00</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p_01</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">joint_entropy</span> <span class="o">-=</span> <span class="n">p_01</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_01</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p_10</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">joint_entropy</span> <span class="o">-=</span> <span class="n">p_10</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_10</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">p_11</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">joint_entropy</span> <span class="o">-=</span> <span class="n">p_11</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_11</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">joint_entropy</span>

<span class="k">def</span> <span class="nf">calculate_mutual_information</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the mutual information between the spike trains of two neurons.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">entropy_neuron1</span> <span class="o">=</span> <span class="n">calculate_entropy</span><span class="p">(</span><span class="n">neuron1</span><span class="p">)</span>
    <span class="n">entropy_neuron2</span> <span class="o">=</span> <span class="n">calculate_entropy</span><span class="p">(</span><span class="n">neuron2</span><span class="p">)</span>
    <span class="n">joint_entropy</span> <span class="o">=</span> <span class="n">calculate_joint_entropy</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">)</span>

    <span class="c1"># Use the formula for mutual information</span>
    <span class="n">mutual_information</span> <span class="o">=</span> <span class="n">entropy_neuron1</span> <span class="o">+</span> <span class="n">entropy_neuron2</span> <span class="o">-</span> <span class="n">joint_entropy</span>

    <span class="k">return</span> <span class="n">mutual_information</span>
</pre></div>
</div>
</div>
</div>
<p>So let’s see what the mutal information is when we re-simulate our neurons back at the original parameter settings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Time and rates</span>
<span class="n">total_time_sec</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">sampling_rate_hz</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="n">total_time_sec</span> <span class="o">*</span> <span class="n">sampling_rate_hz</span>

<span class="c1"># Probabilities</span>
<span class="n">base_firing_prob</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">influence</span> <span class="o">=</span> <span class="mf">0.03</span>
<span class="n">noise_level</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># Simulate the two neurons</span>
<span class="n">neuron1</span> <span class="o">=</span> <span class="n">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">)</span>
<span class="n">neuron2</span> <span class="o">=</span> <span class="n">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="n">influence</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">,</span> <span class="n">neuron1</span><span class="p">)</span>


<span class="c1"># Calculate and print the mutual information</span>
<span class="n">mutual_information</span> <span class="o">=</span> <span class="n">calculate_mutual_information</span><span class="p">(</span><span class="n">neuron2</span><span class="p">,</span> <span class="n">neuron1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mutual Information: </span><span class="si">{</span><span class="n">mutual_information</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This reflects the mutual dependence between the two neurons. You can probably guess what questions we will ask about this.</p>
<section id="question-2-1">
<h3>Question 2.1<a class="headerlink" href="#question-2-1" title="Permalink to this heading">#</a></h3>
<p>Increase the baseline firing rate parameter, <em>base_firing_prob</em>, by a factor of 10 to 0.2. What happens to the mutual information of the neurons? Explain why this effect may or may not occur.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your answer here as a comment. Explain yourself.</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="question-2-2">
<h3>Question 2.2<a class="headerlink" href="#question-2-2" title="Permalink to this heading">#</a></h3>
<p>Put the baseline firing rate parameter back to 0.02. Increase the influence parameter, from neuron 1 to neuron 2, by a factor of 10 to 0.3. What happens to the mutual information of the neurons? Explain why this effect may or may not occur.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your answer here as a comment. Explain yourself.</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="question-2-3">
<h3>Question 2.3<a class="headerlink" href="#question-2-3" title="Permalink to this heading">#</a></h3>
<p>Take the last set of simulations that you ran (with the influence set at 0.3) and switch the order of the neurons in the calculation of mutual information. What does or does not happen to the mutual information estimate? Why?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your answer here as a comment. Explain yourself.</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="section-3-transfer-entropy">
<h2>Section 3 - Transfer entropy<a class="headerlink" href="#section-3-transfer-entropy" title="Permalink to this heading">#</a></h2>
<p>While mutual information reflects the information provided about <span class="math notranslate nohighlight">\(X\)</span> from <span class="math notranslate nohighlight">\(Y\)</span>, it is essentially symmetrical. But we have put a causal relationship in our simulated neurons: neuron 1 <em>influences</em> neuron 2. To get at this causal (in a statistical sense) relationship, we’ll want to estimate the <em>transfer entropy</em> instead.</p>
<p>Recall that transfer entropy describes the statisitcal dependency between past states of a source signal and future states of the receiver signal. Specifically it captures how much information the source has transfered to the receiver: <span class="math notranslate nohighlight">\(T(X \rightarrow Y) = I(Y_{f} ; X_p | Y_p) = H(Y_f|Y_p) - H(Y_f|X_p, Y_p)\)</span></p>
<p>Let’s begin by writting a function to calculate transfer entropy</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_transfer_entropy</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate the transfer entropy from neuron1 to neuron2.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">transfer_entropy</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">neuron1</span><span class="p">)):</span>
        <span class="c1"># The states at time t</span>
        <span class="n">x_t</span> <span class="o">=</span> <span class="n">neuron1</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">y_t</span> <span class="o">=</span> <span class="n">neuron2</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># The state at time t+1</span>
        <span class="n">y_t_plus_1</span> <span class="o">=</span> <span class="n">neuron2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

        <span class="c1"># The joint probabilities</span>
        <span class="n">p_y_t_plus_1_y_t_x_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">neuron2</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">==</span> <span class="n">y_t_plus_1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">neuron2</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_t</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">neuron1</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">x_t</span><span class="p">))</span>
        <span class="n">p_y_t_plus_1_y_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">neuron2</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">==</span> <span class="n">y_t_plus_1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">neuron2</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_t</span><span class="p">))</span>

        <span class="c1"># Avoid division by zero</span>
        <span class="k">if</span> <span class="n">p_y_t_plus_1_y_t</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># The conditional probabilities</span>
            <span class="n">p_conditional_joint</span> <span class="o">=</span> <span class="n">p_y_t_plus_1_y_t_x_t</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">neuron2</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_t</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">neuron1</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">x_t</span><span class="p">))</span>
            <span class="n">p_conditional</span> <span class="o">=</span> <span class="n">p_y_t_plus_1_y_t</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neuron2</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">y_t</span><span class="p">)</span>

            <span class="c1"># The contribution to the transfer entropy</span>
            <span class="n">transfer_entropy</span> <span class="o">+=</span> <span class="n">p_y_t_plus_1_y_t_x_t</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_conditional_joint</span> <span class="o">/</span> <span class="n">p_conditional</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">transfer_entropy</span>
</pre></div>
</div>
</div>
</div>
<p>In order to really see the causal effect let’s ramp up our influence to 0.9 and calculate the transfer entropy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Time and rates</span>
<span class="n">total_time_sec</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">sampling_rate_hz</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="n">total_time_sec</span> <span class="o">*</span> <span class="n">sampling_rate_hz</span>

<span class="c1"># Probabilities</span>
<span class="n">base_firing_prob</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">influence</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">noise_level</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="c1"># Simulate the two neurons</span>
<span class="n">neuron1</span> <span class="o">=</span> <span class="n">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">)</span>
<span class="n">neuron2</span> <span class="o">=</span> <span class="n">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="n">influence</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">,</span> <span class="n">neuron1</span><span class="p">)</span>

<span class="c1"># Calculate and print the transfer entropy</span>
<span class="n">transfer_entropy</span> <span class="o">=</span> <span class="n">calculate_transfer_entropy</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Transfer Entropy from Neuron 1 to Neuron 2: </span><span class="si">{</span><span class="n">transfer_entropy</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Re-run the code cell above multiple times. What do you notice about the estimate of transfer entropy?</p>
<p>Just to get a sense of what is going on, let’s look at our neurons’ behavior by plotting them. What do you see?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the plotting function</span>
<span class="n">plot_spikes</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">,</span> <span class="n">sampling_rate_hz</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Okay, clearly there is something different between neuron 1 and neuron 2, but the transfer entropy measure is noisy. So let’s run a bunch of simulations and plot the results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set the number of simulations</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># Initialize the list to hold transfer entropies</span>
<span class="n">transfer_entropies</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Run the simulation T times</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
    
    <span class="c1"># Simulate the neurons</span>
    <span class="n">neuron1</span> <span class="o">=</span> <span class="n">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">)</span>
    <span class="n">neuron2</span> <span class="o">=</span> <span class="n">simulate_neuron_spikes</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">base_firing_prob</span><span class="p">,</span> <span class="n">influence</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">,</span> <span class="n">neuron1</span><span class="p">)</span>
    
    <span class="c1"># Calculate and print the transfer entropy</span>
    <span class="n">transfer_entropy</span> <span class="o">=</span> <span class="n">calculate_transfer_entropy</span><span class="p">(</span><span class="n">neuron1</span><span class="p">,</span> <span class="n">neuron2</span><span class="p">)</span>
    <span class="n">transfer_entropies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transfer_entropy</span><span class="p">)</span>

<span class="c1"># Plot a histogram of the transfer entropies</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">transfer_entropies</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Histogram of Transfer Entropies&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Transfer Entropy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frequency&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Note that negative transfer entropies are a thing. This is okay. It means that the probability of neuron 2 spiking given that neuron 1 is spiking is lower than the probability that the neurons are independnet. This can sometimes when there are oscillations in the signal (in these simple Poisson process simulations, things that look like oscillation or cross-correlations, but aren’t really, can pop up).</p>
<p>In any case, we should be looking at whether there is structure in the estimates of transfer entropy across simulations and whether it is different from zero. It is clear that we see structure in the transfer entropy from neuron 1 to neuron 2. What is this structure?</p>
<section id="question-3-1">
<h3>Question 3.1<a class="headerlink" href="#question-3-1" title="Permalink to this heading">#</a></h3>
<p>Re-run the previous code cell, but switch the order of the neurons in the calculation of transfer entropy (i.e., estimate the entropy from neuron 2 to neuron 1). What do you see in the distribution of transfer entropy values and why?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your answer here as a comment. Explain yourself.</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="question-3-2">
<h3>Question 3.2<a class="headerlink" href="#question-3-2" title="Permalink to this heading">#</a></h3>
<p>Re-run the batch simulations above, but reduce the influence parameter back down to 0.03. Calculate the transfer entropy from neuron 1 to neuron 2 again. What do you see in the distribution of transfer entropy values and what does this tell you?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write your answer here as a comment. Explain yourself.</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="intro-python.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introduction to python</p>
      </div>
    </a>
    <a class="right-next"
       href="lab2-explorelib.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Lab 2 - Introduction to <em>explorationlib</em></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#background">Background</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-entropy-again"><strong>What is entropy again?</strong></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-between-variables"><strong>Entropy between variables</strong>.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mutual-information-between-variables"><strong>Mutual information between variables</strong>.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#transfer-entropy-between-variables"><strong>Transfer entropy between variables</strong>.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-setup">Section - Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-1-entropy">Section 1 - Entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-our-two-neurons">Visualizing our two neurons</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-1-1">Question 1.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-1-2">Question 1.2</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-2-mutual-information">Section 2 - Mutual information</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-2-1">Question 2.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-2-2">Question 2.2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-2-3">Question 2.3</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#section-3-transfer-entropy">Section 3 - Transfer entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-3-1">Question 3.1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#question-3-2">Question 3.2</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Timothy Verstynen, Erik Peterson, Matthew Clapp, Jack Burgess
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>