{"cells":[{"cell_type":"markdown","metadata":{"id":"NcGnAXGVqQK8"},"source":["# Lab 4 - Evidence Accumulation\n","\n","This lab has two main components designed to go over the process of evidence accumulation.\n","\n","1. Visualize the drift-diffusion model and see how parameters change evidence accumulation.\n","2. Introduce an exploratory agent that accumulates sensory evidence , and explore how the parameters of the DDM influence the performance of the agent"]},{"cell_type":"markdown","source":["## Background\n","\n","Here we will go over the evidence accumulation process. First we will just explore the dynamics of simple accumulation-to-bound processes. Then we will implement an accumulator process to our chemotaxis valentino agent.\n","\n","As a reminder, the accumulation-to-bound process models the drift of an evidence process $\\theta$ whose rate of change is determined by a drift rate $v$, time $t$, and a diffusion noise constant $\\sigma$.\n","\n","$$\\delta\\theta = v \\delta t + \\sigma \\delta W$$\n","\n","Here $W$ is a Wiener noise process. The diffusion of evidence process starts after and onset time $tr$, reflecting sensory delays and it until $\\theta \\geq \\frac{+a}{2}$ or $\\theta \\leq \\frac{-a}{2}$ where $a$ is a threhsold (or boundary height) of evidence. Often $\\theta$ starts at 0 (i.e., unbiased), but can start with a degree of bias $z$.\n","\n","In the simulations we will use for our valentino agents, we will have a 1 dimensional decision. Which means that the process starts at 0 and only continues until it hits the upper boundary $a$ (i.e., stops when $\\theta \\geq a$) as the agent only need to make one deciison: to change or not to change."],"metadata":{"id":"Ue04M5KNwzgU"}},{"cell_type":"markdown","metadata":{"id":"6AYm4pEtH9O6"},"source":["## Section 0 - Setup"]},{"cell_type":"markdown","metadata":{"id":"l_bxUa9ZLcMr"},"source":["First let's set things up for the two parts of the lab."]},{"cell_type":"markdown","metadata":{"id":"H7wZ20Mhm9Dn"},"source":["### Install ADMCode and explorationlib libraries"]},{"cell_type":"markdown","metadata":{"id":"hH9mBm2YLsMz"},"source":["Install the code for running the DDM simulations (ADMCode) and the evidence accumulation agents (explorelib)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZOPw8ouUMI9"},"outputs":[],"source":["# Install explorationlib & gym-maze\n","!pip install --upgrade git+https://github.com/coaxlab/explorationlib.git\n","!pip install --upgrade git+https://github.com/MattChanTK/gym-maze.git\n","!pip install celluloid # for the gifs"]},{"cell_type":"markdown","metadata":{"id":"-7EGUFBznE-w"},"source":["### Import Modules\n","\n","Here we will bring in all the modules and libraries that we will need for this lab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xchYm8E7XD3L"},"outputs":[],"source":["# ADM modules\n","from __future__ import division\n","from ADMCode import visualize as vis\n","from ADMCode import ddm, sdt\n","\n","import numpy as np\n","import pandas as pd\n","\n","from ipywidgets import interactive\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","\n","from copy import deepcopy\n","\n","# Import misc\n","import shutil\n","import glob\n","import os\n","import copy\n","import sys\n","\n","# Vis - 1\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Exp\n","from explorationlib.run import experiment\n","from explorationlib.util import select_exp\n","from explorationlib.util import load\n","from explorationlib.util import save\n","\n","# Agents\n","from explorationlib.agent import DiffusionDiscrete\n","from explorationlib.agent import GradientDiffusionGrid\n","from explorationlib.agent import GradientDiffusionDiscrete\n","from explorationlib.agent import AccumulatorGradientGrid\n","from explorationlib.agent import TruncatedLevyDiscrete\n","\n","# Env\n","from explorationlib.local_gym import ScentGrid\n","from explorationlib.local_gym import create_grid_scent\n","from explorationlib.local_gym import uniform_targets\n","from explorationlib.local_gym import constant_values\n","from explorationlib.local_gym import create_grid_scent_patches\n","\n","# Vis - 2\n","from explorationlib.plot import plot_position2d\n","from explorationlib.plot import plot_length_hist\n","from explorationlib.plot import plot_length\n","from explorationlib.plot import plot_targets2d\n","from explorationlib.plot import plot_scent_grid\n","\n","# Score\n","from explorationlib.score import total_reward\n","from explorationlib.score import num_death"]},{"cell_type":"markdown","metadata":{"id":"zp9GIk4pnIXN"},"source":["### Notebook Config\n","\n","Now let's do some tweaks to get the notebooks to render things nicely."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Udc4lkT1TW7U"},"outputs":[],"source":["# Pretty plots\n","warnings.simplefilter('ignore', np.RankWarning)\n","warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n","warnings.filterwarnings(\"ignore\")\n","sns.set(style='white', font_scale=1.3)\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","%config IPCompleter.greedy=True\n","plt.rcParams[\"axes.facecolor\"] = \"white\"\n","plt.rcParams[\"figure.facecolor\"] = \"white\"\n","plt.rcParams[\"font.size\"] = \"16\"\n","\n","# Dev\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"cy-vC0rLdVV-"},"source":["## Section 1 - Simulating the Drift-Diffusion Model\n","\n","Here, we will visualize the DDM in action and see how changes in its parameters affect the accuracy and reaction times of the decision process.\n","\n","First thing first, let's take a look at the code. It can be found in the Colab virtual machine here: /usr/local/lib/python3.7/dist-packages/ADMCode/ddm.py"]},{"cell_type":"markdown","metadata":{"id":"Lc25fuhYnTip"},"source":["### DDM Parameters\n","\n","Let's start with a simple set of simulations using the parameters below. The parameters get passed to the DDM agent as a numpy array."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOPFsHmAX0E8"},"outputs":[],"source":["a = .05 # boundary height\n","v = -.05 # strong drift-rate\n","tr = .25 # nondecision time (in seconds)\n","z = .5 # starting point ([0,1], fraction of a)\n","\n","dt = .001 # time stepsize\n","si = .1 # sigma (noise scalar)\n","dx = si * np.sqrt(dt) # evidence stepsize (up/down)\n","deadline = 1.75 # max decision time (in sec)\n","ntrials = 1000 # number of trials to simulate\n","\n","parameters = np.array([a, tr, v, z, si, dx, dt])"]},{"cell_type":"markdown","metadata":{"id":"V98ITfR9nWWM"},"source":["### Generating Data\n","\n","The **ddm.sim_ddm_trials** function runs a set of trials (default 500 trials) of a DDM with the parameters specified in your parameters array. Let's try it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iVoozqscaCvB"},"outputs":[],"source":["df, traces = ddm.sim_ddm_trials(parameters, ntrials, deadline)\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"HDRMhQHYNbnl"},"source":["This produced an output object called **traces** that has not only the choice and reactiontime on each trial, but also the information diffusion traces for each run of the DDM.\n","\n","One important thing to note is that in these simulations the upper bound represents the \"correct\" choice, while the lower bound represents \"errors\". So this is what is known as an accuracy coding for the DDM."]},{"cell_type":"markdown","metadata":{"id":"zS41I8-EnZ9n"},"source":["### Analyze simulated behavior"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhbYLnjtaFTB"},"outputs":[],"source":["accuracy = df.choice.mean()\n","corRT = df[df.choice==1].rt.mean()\n","errRT = df[df.choice==0].rt.mean()\n","\n","print(\"RT (cor) = {:.0f} ms\".format(corRT/dt))\n","print(\"RT (err) = {:.0f} ms\".format(errRT/dt))\n","print(\"Accuracy = {:.0f}%\".format(accuracy*100))"]},{"cell_type":"markdown","metadata":{"id":"0S2wGEByNppw"},"source":["As we can see, the DDM is biased towards the upper boundary. What parameter defines this bias in the model that we set up?"]},{"cell_type":"markdown","metadata":{"id":"Mjol5zE5ngXf"},"source":["### Plot evidence traces\n","\n","The ADMCode library has a set of custom visualization tools that allow us to see the DDM in action. Let's take a look at one of them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HVpDIf4caJEJ"},"outputs":[],"source":["ax = vis.plot_ddm_sims(df, parameters, traces=traces, plot_v=True)"]},{"cell_type":"markdown","metadata":{"id":"FyqTZ6wPOngA"},"source":["The plot above shows all fo the traces. Let's see about plotting just the first trial's trace."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBD4hD6I4cbf"},"outputs":[],"source":["ax = vis.plot_ddm_sims(df, parameters, traces=traces[:1], plot_v=True)"]},{"cell_type":"markdown","metadata":{"id":"todEJtDzOueO"},"source":["The example above shows the mean overall drift process trajectory as a solid black line. The single diffusion process plotted is the diffusion process for both trials."]},{"cell_type":"markdown","metadata":{"id":"XDcVW2ioPDDF"},"source":["---\n","### Question 1.1\n","\n","Re-run the simulations above, but with the following parameters:\n","\n","a = .15  \\\\\n","v = -.05 \\\n","tr = .25 \\\\\n","z = .5  \\\\\n","\n","dt = .001 \\\\\n","si = .1  \\\\\n","dx = si * np.sqrt(dt)  \\\\\n","deadline = 1.75 \\\\\n","ntrials = 1000\n","\n","_Question_: How did the behavior of the model change? Be specific. What does this tell you about the nature of the parameters that were changed?"]},{"cell_type":"markdown","source":["__Answer:__\n","\n","_(insert response here)_"],"metadata":{"id":"DSjcBjUTTqcP"}},{"cell_type":"markdown","metadata":{"id":"Bi56EKSaQIqq"},"source":["---\n","### Question 1.2\n","\n","Re-run the simulations above, but go back to the baseline parameters:\n","\n","a = .05  \\\\\n","v = -.05 \\\n","tr = .25 \\\\\n","z = .5  \\\\\n","\n","dt = .001 \\\\\n","si = .1  \\\\\n","dx = si * np.sqrt(dt)  \\\\\n","deadline = 1.75 \\\\\n","ntrials = 1000\n","\n","_Question_: What did changing the boundary height do to the model's behavior? Be specific."]},{"cell_type":"markdown","source":["__Answer:__\n","\n","_(insert response here)_"],"metadata":{"id":"gmXIZ7UqTs-m"}},{"cell_type":"markdown","metadata":{"id":"rPqyuEsgoAxV"},"source":["## Section 2 - Using Sensory Evidence To Explore"]},{"cell_type":"markdown","metadata":{"id":"uKjeNzt_x2CR"},"source":["\n","In this section we take on accumulating evidence as a policy for decision making. Our venue is still chemotaxis, but now our sensors are noisy. The presence of this uncertainty makes decisions--of the kind common to decision theory--a necessity.\n","\n","The agents we will be using are the same as used in the Chemotaxis lab (Lab 3). Look back there to see the structure of the gradient search. But here we will explore something in more detail that we skipped over in that lab: evidence accumulation.\n","\n","\n","## Accumulation of chemosignals\n","\n","Because an accumulator is present, our chemo agent sequentially tries to estimate the scent gradient by sampling the new current location, until the threshold is met.\n","\n","Chemo-accumulators have what we can think of as two cognitive or behavioral steps:\n","\n","1. Use an accumulator to (stabely) estimate the chemo gradient\n","2. Use the gradient to make turning decisions\n","\n","More specifically, the agent alternates between sensory measurement and movement. When the agent senses its environment, it determines the shape of the scent gradient at its current location. Based on the gradient, the agent might change its direction of travel.  Then agent then travels a certain distance in a straight line. When the scent gradient is positive, meaning you are going \"up\" the gradient, the probability of turning is set to _p pos_. When the gradient is negative, the turning probability is set to _p neg_. (See code for an example). If the agents turns, the direction is uniform random. The length of travel before the next sensory measurement is sampled from an exponential distribution just like the _DiffusionDiscrete_\n","\n","\n","The decision to be made is this: is the gradient increasing or decreasing?\n","\n","For this, we'll add a  kind of gradient search that uses a DDM-style accumulator to make decisions about the direction of the gradient. Each time step of the simulation can be spent thinking (accumulating evidence at the current location) _or_ acting (jumping to the next location). We assume an agent can't think and act at the same time.\n","\n","Food for thought: Is it better to spend time rationally accumulating evidence, or is it better to just act?\n","\n","In this section, to really understand the thinking-action trade-off, we'll be looking at the results from the following perspective:\n","- average reward\n","- best reward\n","- total distance travelled\n","- number of deaths*\n","\n","*Any experimental trial which does not lead to finding at least a single target (aka reward) means the exploring agent dies. It's a harsh noisy world we live in, after all.\n","\n","We'll look at a noisy, somewhat target-filled, domain and explore how speed, accuracy, and death rate are influenced by the parameters of our drift-diffusion model."]},{"cell_type":"markdown","metadata":{"id":"E92RbveLVq6Y"},"source":["The code for this agent can be found here /usr/local/lib/python3.7/dist-packages/explorationlib/agent.py. The _AccumulatorGradientGrid_ agent code can be found on line 1090 of the _agents.py_ library."]},{"cell_type":"markdown","metadata":{"id":"ALb83ucKfZ35"},"source":["### Example: Influence of drift rate on performance\n","\n","Based on what you have been told so far, how would you expect increases in the _drift rate_ to affect average rewards, best rewards, and deaths in an open field task, with sparse targets and noisy scents?\n","\n","Here, drift rate can be conceptualized as the fidelity of sensory signal, like a sort of signal-to-noise ratio."]},{"cell_type":"markdown","source":["### Making things a bit more difficult\n","\n","Because we are making \"smarter\" agents we can increase the difficulty of our search problem. We are going to start allowing for signal dropout. What we mean by that is we will make some information disappear... poof! Imagine that scent molecules are decomposing and they just drop out of our substrate randomly.\n","\n","We can control the probability of a scent molecule being detected at any point in space with the *p_scent* parameter.\n","\n","Let's see how this works. First, we can recreate our scent distributions from Lab 2. But we set *p_scent* to 0.1, which means that there is a 10% probabilty of detecting the scent at each point of the grid (or a 90% signal drop out rate)."],"metadata":{"id":"XsIwFteQxnET"}},{"cell_type":"code","source":["target_boundary = (10, 10)\n","amplitude = 1000\n","p_scent = 0.1\n","noise_sigma = 2.0\n","\n","coord, scent = create_grid_scent_patches(target_boundary, p=p_scent, amplitude=amplitude, sigma=noise_sigma)\n","\n","plt.imshow(scent, interpolation=None)"],"metadata":{"id":"fqO9N31NxrOs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["As you can see, it is pretty noisy.\n","\n","So like before, let's average across 100 targets to see what the modal resolvable scent looks like (on average)"],"metadata":{"id":"mmrfzAAbyMnl"}},{"cell_type":"code","source":["amplitude = 1\n","p_scent = 0.1\n","num_samples = 100\n","\n","scents = []\n","for _ in range(num_samples):\n","    coord, scent = create_grid_scent_patches(target_boundary, p=p_scent, amplitude=1, sigma=2)\n","    scents.append(deepcopy(scent))\n","\n","scent = np.sum(scents, axis=0)\n","\n","plt.imshow(scent, interpolation=None)"],"metadata":{"id":"ISS1A0HIyV1G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bgb_lZy0fS5x"},"source":["### Create environment\n","\n","The name of the env for this section is the _ScentGrid_. It basically parses up the continuous space into a grid of steps.\n","\n","Let's add some targets and scents to it. Now we are doing to include the drop out of the scent, setting *p_scent* to 0.5 (50% drop out)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d49GnVpAfBJh"},"outputs":[],"source":["# Shared exp parameters\n","num_steps = 200\n","max_steps = 10\n","seed_value = 5838\n","\n","min_length = 1\n","step_size = 0.1\n","\n","noise_sigma = 2\n","detection_radius = 1\n","num_targets = 250\n","target_boundary = (100, 100)\n","\n","# Env\n","env = ScentGrid(mode=None)\n","env.seed(seed_value)\n","\n","# Targets\n","prng = np.random.RandomState(seed_value)\n","targets = uniform_targets(num_targets, target_boundary, prng=prng)\n","values = constant_values(targets, 1)\n","\n","# Scents\n","amplitude = 1000\n","p_scent = 0.95\n","noise_sigma = 1.0\n","coord, scent = create_grid_scent_patches(target_boundary, p=p_scent, amplitude=amplitude, sigma=noise_sigma)\n","scents = [scent for _ in range(len(targets))]\n","env.add_scents(targets, values, coord, scents, noise_sigma=noise_sigma)"]},{"cell_type":"markdown","metadata":{"id":"OA2kiI-GPGxf"},"source":["First, let's see how our environment looks. Each point represents a food target."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J_OqleEFOw25"},"outputs":[],"source":["plot_boundary = (50, 50)\n","num_experiment = 0\n","ax = None\n","ax = plot_targets2d(\n","    env,\n","    boundary=plot_boundary,\n","    color=\"black\",\n","    alpha=1,\n","    label=\"Targets\",\n","    ax=ax,\n",")"]},{"cell_type":"markdown","source":["So we now have another dimension with which to make our stimulus noisy. Just to make things harder."],"metadata":{"id":"nikGO05hykfp"}},{"cell_type":"markdown","metadata":{"id":"1_T5V_pOfuH2"},"source":["\n","### Drift rates\n","\n","Now let us turn to setting up our agents. We'll play with agents with various rates of evidence accumulation.\n","\n","Using the _env_ defined above explore the following drift rates:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zm6JhR05fNzo"},"outputs":[],"source":["# Our parameters\n","drift_rates = [0.25, 0.75, 1.0, 1.25, 1.5]\n","\n","# For plotting\n","colors = [\"darkgreen\", \"seagreen\", \"cadetblue\", \"steelblue\", \"mediumpurple\"]\n","names = drift_rates # list(range(5))"]},{"cell_type":"markdown","metadata":{"id":"XfcCVh2cQdFm"},"source":["---\n","\\### Question 2.1\n","\n","In the context of this gradient decision that our wandering agent does, what should _increasing_ the drift rate do to the agent's behavior?"]},{"cell_type":"markdown","source":["__Answer:__\n","\n","_(insert response here)_"],"metadata":{"id":"Ahzz9wQDTwQ6"}},{"cell_type":"markdown","metadata":{"id":"_ST92j53gRRP"},"source":["### Run\n","\n","\n","Next we will run 100 experiments for each drift rate.\n","\n","_Note:_ This will take a few minutes to run."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DjNYpQqXgA75"},"outputs":[],"source":["# Exp params\n","threshold = 3.0\n","accumulate_sigma = 1.0\n","\n","num_experiments = 100\n","\n","# Run\n","results = []\n","for i, drift_rate in zip(names, drift_rates):\n","    accum = AccumulatorGradientGrid(\n","        min_length=min_length,\n","        max_steps=max_steps,\n","        drift_rate=drift_rate,\n","        threshold=threshold,\n","        accumulate_sigma=accumulate_sigma\n","    )\n","    accum.seed(seed_value)\n","    # !\n","    exp = experiment(\n","        f\"accum_{i}\",\n","        accum,\n","        env,\n","        num_steps=num_steps,\n","        num_experiments=num_experiments,\n","        dump=False,\n","        split_state=True,\n","        seed=seed_value\n","    )\n","    results.append(exp)"]},{"cell_type":"markdown","metadata":{"id":"XUaG8PAEghNe"},"source":["### Plot an example\n","\n","In order to understand how our different agents, with different drift rates, do we can start with a qualitative analysis. Here we will plot a single trial for each agent."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xp_r9LRtgjBK"},"outputs":[],"source":["plot_boundary = (50, 50)\n","num_experiment = 40\n","ax = None\n","for i, result, color in zip(names, results, colors):\n","    ax = plot_position2d(\n","        select_exp(result, num_experiment),\n","        boundary=plot_boundary,\n","        label=i,\n","        color=color,\n","        alpha=1,\n","        ax=ax,\n","    )\n","ax = plot_targets2d(\n","    env,\n","    boundary=plot_boundary,\n","    color=\"black\",\n","    alpha=1,\n","    label=\"Targets\",\n","    ax=ax,\n",")"]},{"cell_type":"markdown","metadata":{"id":"SVWOOd2nhb-G"},"source":["### Plot several metrics\n","\n","Next let us look at differenet metrics of behavior instead, to get a better idea of what changing the drift rate does.\n","\n","The metrics we will look at are: distance, death, best reward, average reward.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubcbKdYeypbc"},"outputs":[],"source":["# Score\n","scores = []\n","for result in results:\n","    l = 0.0\n","    for r in result:\n","        l += np.sum(r[\"agent_num_step\"])\n","    scores.append(l)\n","\n","# Tabulate\n","m, sd = [], []\n","for s in scores:\n","    m.append(np.mean(s))\n","\n","# -\n","fig = plt.figure(figsize=(5, 5))\n","plt.bar([str(n) for n in names], m, color=\"black\", alpha=0.6)\n","plt.ylabel(\"Total run distance\")\n","plt.xlabel(\"Drift rate\")\n","plt.tight_layout()\n","sns.despine()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-HO7k8tys_V"},"outputs":[],"source":["# Score\n","scores = []\n","for result in results:\n","    scores.append(num_death(result))\n","\n","# -\n","fig = plt.figure(figsize=(5, 5))\n","plt.bar([str(n) for n in names], scores, color=\"black\", alpha=0.6)\n","plt.ylabel(\"Deaths\")\n","plt.xlabel(\"Drift rate\")\n","plt.tight_layout()\n","sns.despine()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jg5VrFNJyulv"},"outputs":[],"source":["# Max Score\n","scores = []\n","for result in results:\n","    r = total_reward(result)\n","    scores.append(r)\n","\n","# Tabulate\n","m = []\n","for s in scores:\n","    m.append(np.max(s))\n","\n","# -\n","fig = plt.figure(figsize=(5, 5))\n","plt.bar([str(n) for n in names], m, color=\"black\", alpha=0.6)\n","plt.ylabel(\"Best agent's score\")\n","plt.xlabel(\"Drift rate\")\n","plt.tight_layout()\n","sns.despine()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sOkEfjcZywLl"},"outputs":[],"source":["# Score\n","scores = []\n","for result in results:\n","    r = total_reward(result)\n","    scores.append(r)\n","\n","# Tabulate\n","m, sd = [], []\n","for s in scores:\n","    m.append(np.mean(s))\n","    sd.append(np.std(s))\n","\n","# Plot means\n","fig = plt.figure(figsize=(6, 3))\n","plt.bar([str(n) for n in names], m, yerr=sd, color=\"black\", alpha=0.6)\n","plt.ylabel(\"Avg. score\")\n","plt.xlabel(\"Drift rate\")\n","plt.tight_layout()\n","sns.despine()\n","\n","# Dists of means\n","fig = plt.figure(figsize=(6, 3))\n","for (i, s, c) in zip(names, scores, colors):\n","    plt.hist(s, label=i, color=c, alpha=0.5, bins=list(range(1,50,1)))\n","    plt.legend()\n","    plt.ylabel(\"Frequency\")\n","    plt.xlabel(\"Score\")\n","    plt.tight_layout()\n","    sns.despine()"]},{"cell_type":"markdown","metadata":{"id":"H9oM-BLkSptP"},"source":["---\n","### Question 2.2\n","\n","Describe how increasing the drift rate changes the overall performance of the agent along the dimensions we just plotted. What does this tell you about how the drift rate is changing behavior?"]},{"cell_type":"markdown","source":["__Answer:__\n","\n","_(insert response here)_"],"metadata":{"id":"TxQ-HX51Tyzl"}},{"cell_type":"markdown","metadata":{"id":"FaW1YoUiTArh"},"source":["---\n","### Question 2.3\n","\n","Re-run the simulations above, instead keeping the drift rate at 1.0, and varying the _threshold_ parameter (aka- boundary height) as:\n","\n","thresholds = [2.0, 2.5, 3.0, 3.5, 4.0]\n","\n","\n","_Question_: How does changing the threshold impact performance of the agent and how does this differ from the drift rate?"]},{"cell_type":"markdown","source":["__Answer:__\n","\n","_(insert response here)_"],"metadata":{"id":"pcPa0UuMT1Rh"}},{"cell_type":"markdown","source":["\n","---\n","**IMPORTANT** Did you collaborate with anyone on this assignment, or use LLMs like ChatGPT? If so, list their names here.\n","> *Write Name(s) here*"],"metadata":{"id":"LAXWYNefJJUz"}}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}