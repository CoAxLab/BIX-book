{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcGnAXGVqQK8"
   },
   "source": [
    "# Lab 4 - Evidence Accumulation\n",
    "\n",
    "This lab has two main components designed to go over the process of evidence accumulation.\n",
    "\n",
    "1. Visualize the drift-diffusion model and see how parametes change evidence accumulation.\n",
    "2. Introduce an exploratory agent that accumulates sensory evidence , and explore how the parameters of the DDM influence the performance of the agent\n",
    "\n",
    "Note that this lab re-uses agents we had in the last lab, but explores them in much mroe detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AYm4pEtH9O6"
   },
   "source": [
    "## Section - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_bxUa9ZLcMr"
   },
   "source": [
    "First let's set things up for the two parts of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7wZ20Mhm9Dn"
   },
   "source": [
    "### Install ADMCode and explorationlib libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH9mBm2YLsMz"
   },
   "source": [
    "Install the code for running the DDM simulations (ADMCode) and the evidence accumulation agents (explorelib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mIcWU-2GmQLK"
   },
   "outputs": [],
   "source": [
    "# ADMCode first\n",
    "# !pip install --upgrade git+https://github.com/coaxlab/AdaptiveDecisionMaking_2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4ZOPw8ouUMI9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/coaxlab/explorationlib\n",
      "  Cloning https://github.com/coaxlab/explorationlib to /private/var/folders/5f/qgnj7zxj3d93s_5ccghgk2_m0000gn/T/pip-req-build-e1tmq294\n",
      "  Running command git clone -q https://github.com/coaxlab/explorationlib /private/var/folders/5f/qgnj7zxj3d93s_5ccghgk2_m0000gn/T/pip-req-build-e1tmq294\n",
      "Collecting git+https://github.com/MattChanTK/gym-maze.git\n",
      "  Cloning https://github.com/MattChanTK/gym-maze.git to /private/var/folders/5f/qgnj7zxj3d93s_5ccghgk2_m0000gn/T/pip-req-build-78i49adn\n",
      "  Running command git clone -q https://github.com/MattChanTK/gym-maze.git /private/var/folders/5f/qgnj7zxj3d93s_5ccghgk2_m0000gn/T/pip-req-build-78i49adn\n",
      "Requirement already satisfied: gym in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from gym-maze==0.4) (0.26.2)\n",
      "Requirement already satisfied: pygame in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from gym-maze==0.4) (2.5.0)\n",
      "Requirement already satisfied: numpy in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from gym-maze==0.4) (1.20.3)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from gym->gym-maze==0.4) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from gym->gym-maze==0.4) (4.8.1)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from gym->gym-maze==0.4) (1.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym->gym-maze==0.4) (3.5.0)\n",
      "Requirement already satisfied: celluloid in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: matplotlib in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from celluloid) (3.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from matplotlib->celluloid) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from matplotlib->celluloid) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from matplotlib->celluloid) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from matplotlib->celluloid) (8.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from matplotlib->celluloid) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from matplotlib->celluloid) (1.20.3)\n",
      "Requirement already satisfied: six in /Users/gabrielsarch/anaconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->celluloid) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Explorelib second\n",
    "!pip install --upgrade git+https://github.com/coaxlab/explorationlib\n",
    "!pip install --upgrade git+https://github.com/MattChanTK/gym-maze.git\n",
    "!pip install celluloid # for the gifs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7EGUFBznE-w"
   },
   "source": [
    "### Import Modules\n",
    "\n",
    "Here we will bring in all the modules and libraries that we will need for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hyRNVQHPa5aT"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ADMCode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5f/qgnj7zxj3d93s_5ccghgk2_m0000gn/T/ipykernel_10606/1280288332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mADMCode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mADMCode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mddm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ADMCode'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from ADMCode import visualize as vis\n",
    "from ADMCode import ddm, sdt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ipywidgets import interactive\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xchYm8E7XD3L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabrielsarch/anaconda3/lib/python3.8/site-packages/explorationlib/run.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import misc\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "# Vis - 1\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exp\n",
    "from explorationlib.run import experiment\n",
    "from explorationlib.util import select_exp\n",
    "from explorationlib.util import load\n",
    "from explorationlib.util import save\n",
    "\n",
    "# Agents\n",
    "from explorationlib.agent import DiffusionDiscrete\n",
    "from explorationlib.agent import GradientDiffusionGrid\n",
    "from explorationlib.agent import GradientDiffusionDiscrete\n",
    "from explorationlib.agent import AccumulatorGradientGrid\n",
    "from explorationlib.agent import TruncatedLevyDiscrete\n",
    "\n",
    "# Env\n",
    "from explorationlib.local_gym import ScentGrid\n",
    "from explorationlib.local_gym import create_grid_scent\n",
    "from explorationlib.local_gym import uniform_targets\n",
    "from explorationlib.local_gym import constant_values\n",
    "\n",
    "# Vis - 2\n",
    "from explorationlib.plot import plot_position2d\n",
    "from explorationlib.plot import plot_length_hist\n",
    "from explorationlib.plot import plot_length\n",
    "from explorationlib.plot import plot_targets2d\n",
    "from explorationlib.plot import plot_scent_grid\n",
    "\n",
    "# Score\n",
    "from explorationlib.score import total_reward\n",
    "from explorationlib.score import num_death"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zp9GIk4pnIXN"
   },
   "source": [
    "### Notebook Config\n",
    "\n",
    "Now let's do some tweaks to get the notebooks to render things nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Udc4lkT1TW7U"
   },
   "outputs": [],
   "source": [
    "# Pretty plots\n",
    "warnings.simplefilter('ignore', np.RankWarning)\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(style='white', font_scale=1.3)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "%config IPCompleter.greedy=True\n",
    "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"figure.facecolor\"] = \"white\"\n",
    "plt.rcParams[\"font.size\"] = \"16\"\n",
    "\n",
    "# Dev\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cy-vC0rLdVV-"
   },
   "source": [
    "## Section 1 - Simulating the Drift-Diffusion Model\n",
    "\n",
    "Here, we will visualize the DDM in action and see how changes in its parameters affect the accuracy and reaction times of the decision process.\n",
    "\n",
    "First thing first, let's take a look at the code. It can be found in the Colab virtual machine here: /usr/local/lib/python3.7/dist-packages/ADMCode/ddm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lc25fuhYnTip"
   },
   "source": [
    "### DDM Parameters\n",
    "\n",
    "Let's start with a simple set of simulations using the parameters below. The parameters get passed to the DDM agent as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOPFsHmAX0E8"
   },
   "outputs": [],
   "source": [
    "a = .05 # boundary height\n",
    "v = -.05 # strong drift-rate\n",
    "tr = .25 # nondecision time (in seconds)\n",
    "z = .5 # starting point ([0,1], fraction of a)\n",
    "\n",
    "dt = .001 # time stepsize\n",
    "si = .1 # sigma (noise scalar)\n",
    "dx = si * np.sqrt(dt) # evidence stepsize (up/down)\n",
    "deadline = 1.75 # max decision time (in sec)\n",
    "ntrials = 1000 # number of trials to simulate\n",
    "\n",
    "parameters = np.array([a, tr, v, z, si, dx, dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V98ITfR9nWWM"
   },
   "source": [
    "### Generating Data\n",
    "\n",
    "The **ddm.sim_ddm_trials** function runs a set of trials (default 500 trials) of a DDM with the parameters specified in your parameters array. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVoozqscaCvB"
   },
   "outputs": [],
   "source": [
    "df, traces = ddm.sim_ddm_trials(parameters, ntrials, deadline)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDRMhQHYNbnl"
   },
   "source": [
    "This produced an output object called **traces** that has not only the choice and reactiontime on each trial, but also the information diffusion traces for each run of the DDM.\n",
    "\n",
    "One important thing to note is that in these simulations the upper bound represents the \"correct\" choice, while the lower bound represents \"errors\". So this is what is known as an accuracy coding for the DDM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS41I8-EnZ9n"
   },
   "source": [
    "### Analyze simulated behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhbYLnjtaFTB"
   },
   "outputs": [],
   "source": [
    "accuracy = df.choice.mean()\n",
    "corRT = df[df.choice==1].rt.mean()\n",
    "errRT = df[df.choice==0].rt.mean()\n",
    "\n",
    "print(\"RT (cor) = {:.0f} ms\".format(corRT/dt))\n",
    "print(\"RT (err) = {:.0f} ms\".format(errRT/dt))\n",
    "print(\"Accuracy = {:.0f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0S2wGEByNppw"
   },
   "source": [
    "As we can see, the DDM is biased towards the upper boundary. What parameter defines this bias in the model that we set up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mjol5zE5ngXf"
   },
   "source": [
    "### Plot evidence traces\n",
    "\n",
    "The ADMCode library has a set of custom visualization tools that allow us to see the DDM in action. Let's take a look at one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVpDIf4caJEJ"
   },
   "outputs": [],
   "source": [
    "ax = vis.plot_ddm_sims(df, parameters, traces=traces, plot_v=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyqTZ6wPOngA"
   },
   "source": [
    "The plot above shows all fo the traces. Let's see about plotting just the first trial's trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBD4hD6I4cbf"
   },
   "outputs": [],
   "source": [
    "ax = vis.plot_ddm_sims(df, parameters, traces=traces[:1], plot_v=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "todEJtDzOueO"
   },
   "source": [
    "The example above shows the mean overall drift process trajectory as a solid black line. The single diffusion process plotted is the diffusion process for both trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDcVW2ioPDDF"
   },
   "source": [
    "### Question 1.1\n",
    "\n",
    "Re-run the simulations above, but with the following parameters:\n",
    "\n",
    "a = .15  \\\\\n",
    "v = -.05 \\\n",
    "tr = .25 \\\\\n",
    "z = .5  \\\\\n",
    "\n",
    "dt = .001 \\\\\n",
    "si = .1  \\\\\n",
    "dx = si * np.sqrt(dt)  \\\\\n",
    "deadline = 1.75 \\\\\n",
    "ntrials = 1000\n",
    "\n",
    "_Question_: How did the behavior of the model change? Be specific. What does this tell you about the nature of the parameters that were changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8froG5hQGru"
   },
   "outputs": [],
   "source": [
    "# Write your answer here, as a python comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bi56EKSaQIqq"
   },
   "source": [
    "### Question 1.2\n",
    "\n",
    "Re-run the simulations above, but with the following parameters:\n",
    "\n",
    "a = .05  \\\\\n",
    "v = -.05 \\\n",
    "tr = .25 \\\\\n",
    "z = .5  \\\\\n",
    "\n",
    "dt = .001 \\\\\n",
    "si = .1  \\\\\n",
    "dx = si * np.sqrt(dt)  \\\\\n",
    "deadline = 1.75 \\\\\n",
    "ntrials = 1000\n",
    "\n",
    "_Question_: What did changing the boundary height do to the model's behavior? Be specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wlRsKrS9QVT4"
   },
   "outputs": [],
   "source": [
    "# Write your answer here, as a python comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPqyuEsgoAxV"
   },
   "source": [
    "## Section 2 - Using Sensory Evidence To Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKjeNzt_x2CR"
   },
   "source": [
    "\n",
    "In this section we take on accumulating evidence as a policy for decision making. Our venue is still chemotaxis, but now our sensors are noisy. The presence of this uncertainty makes decisions--of the kind common to decision theory--a necessity.\n",
    "\n",
    "The agents we will be using are the same as used in the Chemotaxis lab (Lab 3). Look back there to see the structure of the gradient search. But here we will explore something in more detail that we skipped over in that lab: evidence accumulation.\n",
    "\n",
    "\n",
    "## Accumulation of chemosignals\n",
    "\n",
    "Because an accumulator is present, our chemo agent sequentially tries to estimate the scent gradient by sampling the new current location, until the threshold is met.\n",
    "\n",
    "Chemo-accumulators have what we can think of as two cognitive or behavioral steps:\n",
    "\n",
    "1. Use an accumulator to (stabely) estimate the chemo gradient\n",
    "2. Use the gradient to make turning decisions\n",
    "\n",
    "More specifically, the agent alternates between sensory measurement and movement. When the agent senses its environment, it determines the shape of the scent gradient at its current location. Based on the gradient, the agent might change its direction of travel.  Then agent then travels a certain distance in a straight line. When the scent gradient is positive, meaning you are going \"up\" the gradient, the probability of turning is set to _p pos_. When the gradient is negative, the turning probability is set to _p neg_. (See code for an example). If the agents turns, the direction is uniform random. The length of travel before the next sensory measurement is sampled from an exponential distribution just like the _DiffusionDiscrete_\n",
    "\n",
    "\n",
    "The decision to be made is this: is the gradient increasing or decreasing?\n",
    "\n",
    "For this, we'll add a  kind of gradient search that uses a DDM-style accumulator to make decisions about the direction of the gradient. Each time step of the simulation can be spent thinking (accumulating evidence at the current location) _or_ acting (jumping to the next location). We assume an agent can't think and act at the same time.\n",
    "\n",
    "Food for thought: Is it better to spend time rationally accumulating evidence, or is it better to just act?\n",
    "\n",
    "In this section, to really understand the thinking-action trade-off, we'll be looking at the results from the following perspective:\n",
    "- average reward\n",
    "- best reward\n",
    "- total distance travelled\n",
    "- number of deaths*\n",
    "\n",
    "*Any experimental trial which does not lead to finding at least a single target (aka reward) means the exploring agent dies. It's a harsh noisy world we live in, after all.\n",
    "\n",
    "We'll look at a noisy, somewhat target-filled, domain and explore how speed, accuracy, and death rate are influenced by the parameters of our drift-diffusion model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E92RbveLVq6Y"
   },
   "source": [
    "The code for this agent can be found here /usr/local/lib/python3.7/dist-packages/explorationlib/agent.py. The _AccumulatorGradientGrid_ agent code can be found on line 1090 of the _agents.py_ library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALb83ucKfZ35"
   },
   "source": [
    "### Example: Influence of drift rate on performance\n",
    "\n",
    "Based on what you have been told so far, how would you expect increases in the _drift rate_ to affect average rewards, best rewards, and deaths in an open field task, with sparse targets and noisy scents?\n",
    "\n",
    "Here, drift rate can be conceptualized as the fidelity of sensory signal, like a sort of signal-to-noise ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgb_lZy0fS5x"
   },
   "source": [
    "### Create environment\n",
    "\n",
    "The name of the env for this section is the _ScentGrid_. It basically parses up the continuous space into a grid of steps.\n",
    "\n",
    "Let's add some targets and scents to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d49GnVpAfBJh"
   },
   "outputs": [],
   "source": [
    "# Shared exp parameters\n",
    "num_steps = 200\n",
    "max_steps = 10\n",
    "seed_value = 5838\n",
    "\n",
    "min_length = 1\n",
    "step_size = 0.1\n",
    "\n",
    "noise_sigma = 2\n",
    "detection_radius = 1\n",
    "num_targets = 250\n",
    "target_boundary = (100, 100)\n",
    "\n",
    "# Env\n",
    "env = ScentGrid(mode=None)\n",
    "env.seed(seed_value)\n",
    "\n",
    "# Targets\n",
    "prng = np.random.RandomState(seed_value)\n",
    "targets = uniform_targets(num_targets, target_boundary, prng=prng)\n",
    "values = constant_values(targets, 1)\n",
    "\n",
    "# Scents\n",
    "coord, scent = create_grid_scent(target_boundary, amplitude=1, sigma=10)\n",
    "scents = [scent for _ in range(len(targets))]\n",
    "env.add_scents(targets, values, coord, scents, noise_sigma=noise_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OA2kiI-GPGxf"
   },
   "source": [
    "First, let's see how our environment looks. Each point represents a food target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_OqleEFOw25"
   },
   "outputs": [],
   "source": [
    "plot_boundary = (50, 50)\n",
    "num_experiment = 0\n",
    "ax = None\n",
    "ax = plot_targets2d(\n",
    "    env,\n",
    "    boundary=plot_boundary,\n",
    "    color=\"black\",\n",
    "    alpha=1,\n",
    "    label=\"Targets\",\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_T5V_pOfuH2"
   },
   "source": [
    "\n",
    "### Drift rates\n",
    "\n",
    "Now let us turn to setting up our agents. We'll play with agents with various rates of evidence accumulation.\n",
    "\n",
    "Using the _env_ defined above explore the following drift rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm6JhR05fNzo"
   },
   "outputs": [],
   "source": [
    "# Our parameters\n",
    "drift_rates = [0.25, 0.75, 1.0, 1.25, 1.5]\n",
    "\n",
    "# For plotting\n",
    "colors = [\"darkgreen\", \"seagreen\", \"cadetblue\", \"steelblue\", \"mediumpurple\"]\n",
    "names = drift_rates # list(range(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfcCVh2cQdFm"
   },
   "source": [
    "### Question 2.1\n",
    "\n",
    "In the context of this gradient decision that our wandering agent does, what should _increasing_ the drift rate do to the agent's behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SkEFTWMQsMS"
   },
   "outputs": [],
   "source": [
    "# Write your answer here, as a python comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ST92j53gRRP"
   },
   "source": [
    "### Run\n",
    "\n",
    "\n",
    "Next we will run 100 experiments for each drift rate.\n",
    "\n",
    "_Note:_ This will take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjNYpQqXgA75"
   },
   "outputs": [],
   "source": [
    "# Exp params\n",
    "threshold = 3.0\n",
    "accumulate_sigma = 1.0\n",
    "\n",
    "num_experiments = 100\n",
    "\n",
    "# Run\n",
    "results = []\n",
    "for i, drift_rate in zip(names, drift_rates):\n",
    "    accum = AccumulatorGradientGrid(\n",
    "        min_length=min_length,\n",
    "        max_steps=max_steps,\n",
    "        drift_rate=drift_rate,\n",
    "        threshold=threshold,\n",
    "        accumulate_sigma=accumulate_sigma\n",
    "    )\n",
    "    accum.seed(seed_value)\n",
    "    # !\n",
    "    exp = experiment(\n",
    "        f\"accum_{i}\",\n",
    "        accum,\n",
    "        env,\n",
    "        num_steps=num_steps,\n",
    "        num_experiments=num_experiments,\n",
    "        dump=False,\n",
    "        split_state=True,\n",
    "        seed=seed_value\n",
    "    )\n",
    "    results.append(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUaG8PAEghNe"
   },
   "source": [
    "### Plot an example\n",
    "\n",
    "In order to understand how our different agents, with different drift rates, do we can start with a qualitative analysis. Here we will plot a single trial for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xp_r9LRtgjBK"
   },
   "outputs": [],
   "source": [
    "plot_boundary = (50, 50)\n",
    "num_experiment = 40\n",
    "ax = None\n",
    "for i, result, color in zip(names, results, colors):\n",
    "    ax = plot_position2d(\n",
    "        select_exp(result, num_experiment),\n",
    "        boundary=plot_boundary,\n",
    "        label=i,\n",
    "        color=color,\n",
    "        alpha=1,\n",
    "        ax=ax,\n",
    "    )\n",
    "ax = plot_targets2d(\n",
    "    env,\n",
    "    boundary=plot_boundary,\n",
    "    color=\"black\",\n",
    "    alpha=1,\n",
    "    label=\"Targets\",\n",
    "    ax=ax,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVWOOd2nhb-G"
   },
   "source": [
    "### Plot several metrics\n",
    "\n",
    "Next let us look at differenet metrics of behavior instead, to get a better idea of what changing the drift rate does.\n",
    "\n",
    "The metrics we will look at are: distance, death, best reward, average reward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubcbKdYeypbc"
   },
   "outputs": [],
   "source": [
    "# Score\n",
    "scores = []\n",
    "for result in results:\n",
    "    l = 0.0\n",
    "    for r in result:\n",
    "        l += r[\"agent_total_l\"][-1]\n",
    "    scores.append(l)\n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for s in scores:\n",
    "    m.append(np.mean(s))\n",
    "\n",
    "# -\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.bar([str(n) for n in names], m, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Total distance\")\n",
    "plt.xlabel(\"Drift rate\")\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-HO7k8tys_V"
   },
   "outputs": [],
   "source": [
    "# Score\n",
    "scores = []\n",
    "for result in results:\n",
    "    scores.append(num_death(result))\n",
    "\n",
    "# -\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.bar([str(n) for n in names], scores, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Deaths\")\n",
    "plt.xlabel(\"Drift rate\")\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jg5VrFNJyulv"
   },
   "outputs": [],
   "source": [
    "# Max Score\n",
    "scores = []\n",
    "for result in results:\n",
    "    r = total_reward(result)\n",
    "    scores.append(r)\n",
    "\n",
    "# Tabulate\n",
    "m = []\n",
    "for s in scores:\n",
    "    m.append(np.max(s))\n",
    "\n",
    "# -\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.bar([str(n) for n in names], m, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Best agent's score\")\n",
    "plt.xlabel(\"Drift rate\")\n",
    "plt.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOkEfjcZywLl"
   },
   "outputs": [],
   "source": [
    "# Score\n",
    "scores = []\n",
    "for result in results:\n",
    "    r = total_reward(result)\n",
    "    scores.append(r)\n",
    "\n",
    "# Tabulate\n",
    "m, sd = [], []\n",
    "for s in scores:\n",
    "    m.append(np.mean(s))\n",
    "    sd.append(np.std(s))\n",
    "\n",
    "# Plot means\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "plt.bar([str(n) for n in names], m, yerr=sd, color=\"black\", alpha=0.6)\n",
    "plt.ylabel(\"Avg. score\")\n",
    "plt.xlabel(\"Drift rate\")\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "\n",
    "# Dists of means\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "for (i, s, c) in zip(names, scores, colors):\n",
    "    plt.hist(s, label=i, color=c, alpha=0.5, bins=list(range(1,50,1)))\n",
    "    plt.legend()\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Score\")\n",
    "    plt.tight_layout()\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9oM-BLkSptP"
   },
   "source": [
    "### Question 2.2\n",
    "\n",
    "Describe how increasing the drift rate changes the overall performance of the agent along the dimensions we just plotted. What does this tell you about how the drift rate is changing behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GPIYWlQ5S_P_"
   },
   "outputs": [],
   "source": [
    "# Write your answer here, as a python comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaW1YoUiTArh"
   },
   "source": [
    "### Question 2.3\n",
    "\n",
    "Re-run the simulations above, instead keeping the drift rate at 1.0, and varying the _threshold_ parameter (aka- boundary height) as:\n",
    "\n",
    "thresholds = [2.0, 2.5, 3.0, 3.5, 4.0]\n",
    "\n",
    "\n",
    "_Question_: How does changing the threshold impact performance of the agent and how does this differ from the drift rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DnuHqPPMTvzz"
   },
   "outputs": [],
   "source": [
    "# Write your answer here, as a python comment"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
