{"cells":[{"cell_type":"markdown","metadata":{"id":"5cmfVFVFVXu-"},"source":["# **Exercise 3: CBGT networks and predator-prey dynamics**\n","\n","## Getting started\n","\n","This homework will involve concepts from the labs we've gone over in class. Feel free to reference them as you complete the assignment.\n","\n","This homework contains 2 sections:\n","1. Simulating decisions in the CBGT network uner stronger direct vs indirect pathway gain.\n","1. Simulating predator-prey dynamics under varying prey behavior when the predator moves actively towards the prey.\n","\n","Fill out the code cells below and answer the questions to complete the assignment. Most of the programming is quite straightforward, as it is all based on code from the labs, which you can use/modify in this notebook."]},{"cell_type":"markdown","metadata":{"id":"34x6j5sNWyNb"},"source":["\n","---\n","## Part 1 - CBGT decision simulations [51 pt]\n","\n","Here you will be adapting the Lab 5 code so that you increase the indirect *and* direct pathways gains by 33% (we did 10% in class). This will give a clearer visualization of how these two pathways control the overall reaction times when you plot their joint histogram."]},{"cell_type":"markdown","metadata":{"id":"W8UtFYFbb5Dz"},"source":["\n","In the code cells below, fill in (and run) code according to the text instructions before each one. Refer to lab 5 for help."]},{"cell_type":"markdown","metadata":{"id":"7t8iBbX6GT6h"},"source":["#### Change Colab's working directory to the `/content` folder using the `cd` command"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3Nd_c1bla9-"},"outputs":[],"source":["cd /content"]},{"cell_type":"markdown","metadata":{"id":"7H53-e--GfTY"},"source":["#### Clone in the CBGT library from https://github.com/CoAxLab/CBGT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SYJXq9sFld1U"},"outputs":[],"source":["!git clone https://github.com/CoAxLab/CBGT"]},{"cell_type":"markdown","metadata":{"id":"mC5n1BEuGuSC"},"source":["#### Change Colab's working directory to the `/content/CBGT` folder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"leVpfmAKlglE"},"outputs":[],"source":["cd /content/CBGT"]},{"cell_type":"markdown","metadata":{"id":"8LTf0s8TG3HG"},"source":["#### Import the necessary modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GeeYUvKdljRC"},"outputs":[],"source":["# import libraries and configure plots\n","\n","import os, sys\n","import pandas as pd\n","import numpy as np\n","import random\n","from future.utils import listvalues\n","from copy import deepcopy\n","\n","import cbgt.netgen as ng\n","import cbgt.analyzefx as afx\n","from cbgt import vis, sim\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","\n","warnings.simplefilter('ignore', np.RankWarning)\n","warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n","warnings.filterwarnings(\"ignore\")\n","\n","%matplotlib inline\n","clrs = ['#347fff', '#febe08']\n","eclrs = ['#1657de', '#f5a005']\n","\n","rc = {'lines.solid_capstyle': u'butt'}\n","sns.set(style='ticks', rc=rc, font_scale=1.4)"]},{"cell_type":"markdown","metadata":{"id":"GayHWBZSHWv4"},"source":["#### Specify the saving directory and set default model parameters/weights exactly as we did in the CBGT lab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCEQD_TJlkjT"},"outputs":[],"source":["# specify saving directory\n","\n","parentDir = 'cbgtDemoTEST'\n","savedir = os.path.join(os.path.expanduser('~'), parentDir)\n","if not os.path.isdir(savedir):\n","    os.mkdir(savedir)\n","\n","# specify certain model parameters\n","\n","BaseStim = 0\n","Stim = 2.54\n","Dynamic = 30.0\n","Choices = 2\n","rampingCTX = True\n","popscale = .3\n","Start=200\n","\n","# save dMSN/iMSN weight presets for each choice\n","\n","presetLow = ng.set_post_learning_weights(dMSN=[1.01, 0.99], iMSN=[1.0,1.0])\n","presetHi = ng.set_post_learning_weights(dMSN=[1.03, 0.98], iMSN=[1.0,1.0])\n","presets = [presetLow, presetHi]\n","\n","conds = ['low', 'high']\n","condABC = ['a', 'b']\n","cond12 = [1, 2]\n","\n","savedirs = [os.path.join(savedir, c) for c in conds]\n","saveLow, saveHi = savedirs\n","saveTest=os.path.join(savedir, 'test')\n","\n","presetDict = dict(zip(conds, presets))\n","condOrder = dict(zip(conds, condABC))\n","condLevel = dict(zip(conds+['test'], cond12+[0]))"]},{"cell_type":"markdown","metadata":{"id":"GCPaducTHm1C"},"source":["#### Define the helping functions for getting sampling parameters, sampling region activations, and building a single network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xUjj5Cvalp6K"},"outputs":[],"source":["# helper functions to specify connection efficiacies for certain pathways\n","\n","def get_sampling_params(scale, direct_strength, indirect_strength):\n","\n","    # set strengths of background inputs/currents\n","    CxSTR      =    0.2\n","    CxTh       =    0.03\n","    CxFSI      =    0.165\n","    D1STR_GPi  =    direct_strength * 1.10\n","    D2STR_GPeP =    indirect_strength * 1.65\n","    STN_GPeP_A =    0.07\n","    STN_GPeP_N =    4.01\n","    STN_GPi    =    0.0324\n","    GPi_Th     =    0.067\n","    ThSTR      =    0.34\n","    ThCx       =    0.02\n","\n","    mu = dict(Cx={'STR':CxSTR, 'Th':CxTh, 'FSI':CxFSI},\n","                Th={'STR':ThSTR, 'Cx':ThCx},\n","                D1STR={'GPi': D1STR_GPi},\n","                D2STR={'GPeP': D2STR_GPeP},\n","                STN={'GPi': STN_GPi},\n","                GPi={'Th': GPi_Th})\n","    sd = {i:{j: mu[i][j]*scale for j in list(mu[i])} for i in list(mu)}\n","    return mu, sd\n","\n","# assign the background inputs to each brain region accordingly\n","def sample_network_efficacies(muEff, sdEff, N):\n","    X = {}\n","    nuclei = list(muEff)\n","    for i in nuclei:\n","        targets = list(muEff[i])\n","        X[i] = {}\n","        for j in targets:\n","            X[i][j] = np.random.normal(muEff[i][j], sdEff[i][j], N)\n","    return X\n","\n","# build the network with specified connections\n","def build_single_network(X, idx=0):\n","\n","    Cx={'STR': X['Cx']['STR'][idx],\n","        'Th': X['Cx']['Th'][idx],\n","        'FSI': X['Cx']['FSI'][idx]}\n","\n","    D1STR={'GPi': X['D1STR']['GPi'][idx]}\n","    D2STR={'GPeP': X['D2STR']['GPeP'][idx]}\n","\n","    STN={'GPi': X['STN']['GPi'][idx]}\n","\n","    GPi={'Th': X['GPi']['Th'][idx]}\n","\n","    Th={'STR': X['Th']['STR'][idx],\n","        'Cx': X['Th']['Cx'][idx]}\n","\n","    return ng.getConEff(Cx=Cx, D1STR=D1STR, D2STR=D2STR, STN=STN, GPi=GPi, Th=Th)"]},{"cell_type":"markdown","metadata":{"id":"OzEIwcelIJ6T"},"source":["#### Code for defining the function for running a batch of simulations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bE6jhSJltFZ"},"outputs":[],"source":["# code to run a batch of simulations\n","\n","def runBatch(batch_size, direct_strength, indirect_strength, parallel = 1):\n","  N_subj = 1\n","  sdScale = 0\n","\n","  conProb = ng.getConProb()\n","  muEff, sdEff = get_sampling_params(sdScale, direct_strength, indirect_strength)\n","  X = sample_network_efficacies(muEff, sdEff, N=N_subj)\n","  subj_eff_dicts = [build_single_network(X, idx=i) for i in range(N_subj)]\n","  idx = 0\n","  conEff_i = subj_eff_dicts[idx]\n","\n","  stim = 2.5\n","  preset = presetDict['low']\n","\n","  ng.setDirectory(saveTest)\n","\n","  np.random.seed(seed=np.random.randint(0,1000))\n","  sweepcount = ng.configureSweep(0, experiment='mc', preset=preset, Start=Start,\n","                                popscale=popscale, BaseStim=BaseStim, Choices=Choices,\n","                                WrongStim=stim, RightStim=stim, Dynamic=Dynamic,\n","                                rampingCTX=True,\n","                                conProb=conProb,\n","                                conEff=conEff_i)\n","\n","  ng.compileAndRunSweepALL(batch_size, 0, 1, parallel)"]},{"cell_type":"markdown","metadata":{"id":"WPL_21iRIf1U"},"source":["#### Define the helper function for compiling simulated behavioral data into a dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GA6e7xQelwao"},"outputs":[],"source":["# code to compile the behavioral data into a dataframe\n","\n","def readResults(batch_size):\n","    results = ng.readAllTrialResults(batch_size,0,1)\n","    rtdata = pd.DataFrame(columns=['rt','accuracy'])\n","    for result in results[0][:batch_size]:\n","        temp = ng.findOutputs(result)['decision made']\n","        row = pd.Series({'rt':temp['delay'], 'accuracy':(1-temp['pathvals'][0])})\n","        rtdata = rtdata.append(row, ignore_index=True)\n","    return rtdata"]},{"cell_type":"markdown","metadata":{"id":"U3onPE3_l47r"},"source":["### Code for running your specific batches of simulations"]},{"cell_type":"markdown","metadata":{"id":"lwgaSTlyCJUI"},"source":["#### Set up your batch run parameters with a `batch_size` of 20, with `direct_strength` increased 33% from the default 1.00, and with the standard `indirect_strength` setting of 1.00. [7 pt]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w9zv5QgXmIve"},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{"id":"yzpxm7ifBTAQ"},"source":["#### Run the strengthened direct pathway batch and produce a corresponding dataframe [7 pt]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qA_8CmXFmOp8"},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{"id":"PgClefGrBoYR"},"source":["#### Set up your batch run parameters with a `batch_size` of 20, the standard `direct_strength` of 1.00, but with `indirect_strength` increased by 33%. [7 pt]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BdXfGYemZuZ"},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{"id":"MI3YkSpLBALm"},"source":["#### Run the strengthened indirect pathway batch and produce a corresponding dataframe [7 pt]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y-X8UWmimqnj"},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{"id":"ZWzWqG5T_thb"},"source":["#### For each condition (strengthened direct vs indirect pathway), calculate and print the mean values for *reaction time* and *percent of actions made to the left* (\"accuracy\") [5 pt]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JwT7rt62mVMZ"},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{"id":"g8jp9xvQDR4M"},"source":["#### Plot a histogram of reaction times for the strengthened direct vs. indirect pathway conditions. Make sure to refer to the correct data and include the correct data each time you call the `plt.hist()` function. [6 pt]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1-HSaFYUm1Vm"},"outputs":[],"source":["# Your code here\n"]},{"cell_type":"markdown","metadata":{"id":"l2tmVj4NcFk9"},"source":["\n","### Question 1.1 [6 pt]\n","\n","How what does increasing the relative efficacy of the direct and indirect pathways do to the networks' decision speed? Explain why this occurs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19oG_avscRIw"},"outputs":[],"source":["# Write your answer here, as a python comment\n"]},{"cell_type":"markdown","metadata":{"id":"0tDpTNJSchmY"},"source":["### Question 1.2: [6 pt]\n","Rerun the simulations above but increase the synaptic weight from STN to GPi from 0.0324 to 0.04. How does this influence the outcome of the simulations? Why does this happen?\n","\n","(Hint: if you get an error while running the simulations, this is supposed to happen)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BoXbxtWvc5Bu"},"outputs":[],"source":["# Write your answer here, as a python comment\n"]},{"cell_type":"markdown","metadata":{"id":"RZIuatwoXFSG"},"source":["---\n","## Part 2 - Predator-prey dynamics [49 pt]\n","\n","In this part, you will investigate how different prey behavior effects predator fitness when the predator moves actively towards the prey.\n","\n","In lab 6, we saw how the predator and prey variables can effect their fitness metrics when both followed random movements. Here, we will investigate:\n","1. How agents with differing movement behaviors effect fitness scores when a predator can actively move towards the prey.\n","2. How prey would need to adapt if a superior predator is introduced.\n","\n","You will instantiate a type *GreedyPredatorGrid* predator (see below and explorelib/agents.py for details), and see how prey of types *DiffusionGrid*, *LevyGrid*, and *FreezeLevyGrid* effect predator and prey survival.\n","\n","Here are brief descriptions of each agent type:\n","\n","Predator:\n","1. *GreedyPredatorGrid*: The GreedyPredatorGrid class defines an agent in 2D that, at each time step, calculates and moves greedily towards the closest other agent on the grid, with a possibility to not move based on the parameter *p_move*.\n","\n","Prey:\n","1. *DiffusionGrid*: The agent performs a diffusion search on the grid, taking steps in random directions for lengths sampled from an exponential distribution, constrained by a minimum length and step size.\n","2. *LevyGrid*: The agent conducts a Levy search on the grid, moving in random directions with step lengths determined by a power-law distribution and controlled by a minimum length, step size, and exponent.\n","3. *FreezeLevyGrid*: The agent conducts a Levy search on the grid with a chance to freeze in place instead of turning, determined by a given probability.\n","\n","Please see the *explorationlib/agents.py* file for more information."]},{"cell_type":"markdown","metadata":{"id":"yAC_VXUyefCw"},"source":["### Coding\n","\n","In the code cells below, fill in (and run) code according to the text instructions before each one. Refer to lab 6 for help."]},{"cell_type":"markdown","metadata":{"id":"0WDpufjttrPg"},"source":["#### Install relevant code libraries."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pcFBS7YVqBH2"},"outputs":[],"source":["!pip install --upgrade --no-cache-dir git+https://github.com/CoAxLab/explorationlib\n","!pip install --upgrade git+https://github.com/MattChanTK/gym-maze.git"]},{"cell_type":"markdown","metadata":{"id":"LvtyJbdwt-2G"},"source":["#### Import relevant modules."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZUBZyFYqBoN"},"outputs":[],"source":["import shutil\n","import glob\n","import os\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import explorationlib\n","from explorationlib.agent import DiffusionGrid\n","from explorationlib.agent import LevyGrid\n","from explorationlib.agent import FreezeLevyGrid\n","from explorationlib.agent import GreedyPredatorGrid\n","\n","from explorationlib.local_gym import uniform_targets\n","from explorationlib.local_gym import constant_values\n","from explorationlib.local_gym import CompetitiveGrid\n","\n","from explorationlib.run import multi_experiment\n","from explorationlib.util import select_exp\n","from explorationlib.util import select_agent\n","from explorationlib.util import load\n","from explorationlib.util import save\n","\n","from explorationlib.plot import plot_position2d\n","from explorationlib.plot import plot_positions2d\n","from explorationlib.plot import plot_length_hist\n","from explorationlib.plot import plot_length\n","from explorationlib.plot import plot_targets2d\n","from explorationlib.plot import show_gif\n","\n","from explorationlib import score\n","from explorationlib.score import num_death\n","# from explorationlib.score import average_reward\n","from explorationlib.score import total_reward\n","from explorationlib.score import first_reward"]},{"cell_type":"markdown","metadata":{"id":"MPdgRFgEuGHX"},"source":["#### Set up pretty plots."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hHG7GGwvqEQ9"},"outputs":[],"source":["# Pretty plots\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","%config IPCompleter.greedy=True\n","plt.rcParams[\"axes.facecolor\"] = \"white\"\n","plt.rcParams[\"figure.facecolor\"] = \"white\"\n","plt.rcParams[\"font.size\"] = \"16\"\n","\n","# Dev\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"markdown","metadata":{"id":"j48MazlrNXLa"},"source":["---\n","## Part 2.1 - Prey with different behavior traits\n","\n","In this part we will investigate how agents with differing movement behaviors effect fitness scores."]},{"cell_type":"markdown","metadata":{"id":"GhjgPmCcqQlN"},"source":["### 2.1.1 Investigating prey with different behaviors\n","\n","First, we will investigate how three different types of prey compare against a single type of predator that moves towards the prey."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-LE2vyZkqNxJ"},"outputs":[],"source":["# Shared env params\n","num_steps = 50\n","num_experiments = 50\n","seed_value = 559 # DO NOT TOUCH (for consistent results across students)\n","\n","# Agent parameters\n","# Fast\n","fast_scale = 5\n","fast_min_length = 15\n","fast_step_size = 15\n","\n","# Flight\n","flight_exp = 15\n","flight_step_size = 11\n","\n","# Freeze\n","p_freeze = 0.9\n","freeze_exp = 3\n","freeze_step_size = 8\n","\n","# Predator\n","pred_step_size = 1 # predator step size\n","p_move = 0.9 # probability of moving at each time step\n","detection_radius =  1 # detection radius to kill prey"]},{"cell_type":"markdown","metadata":{"id":"uGiyUwS6r6Ba"},"source":["#### Complete the code below to initialize the prey input variables. Refer to Lab 6 for reference. Fast=*DiffusionGrid*, Flight=*LevyGrid*, Freeze=*FreezeLevyGrid*. The predator code is given to you. [5 pt]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxsAQ1jOqOsp"},"outputs":[],"source":["# Define 9 prey of differing behavior types (Fast=DiffusionGrid, Flight=LevyGrid, Freeze=FreezeLevyGrid). Use the parameters above to define the agents. Refer to Lab 6 for reference.\n","\n","preys = [\n","    [\n","    # Define 3 Fast Prey\n","    # YOUR CODE HERE\n","    ],\n","    [\n","    # Define 3 Flight Prey\n","    # YOUR CODE HERE\n","    ],\n","    [\n","    # Define 3 Freeze Prey\n","    # YOUR CODE HERE\n","    ]\n","]\n","\n","# Define a new predator of type GreedyPredatorGrid (this is done for you)\n","pred = [\n","    GreedyPredatorGrid(\n","        step_size=pred_step_size,\n","        p_move=p_move,\n","    )\n","]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eKFKHSPG-qrE"},"source":["#### Run the experiments for each prey type (nothing to code here)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7tJKf9KsOHf1"},"outputs":[],"source":["conditions = ['Fast', 'Flight', 'Freeze']\n","def run_experiments():\n","  '''\n","  Function to run experiments with defined prey & predators\n","  '''\n","  experiments = []\n","  model_codes = []\n","\n","  for prey in preys:\n","\n","    # All agents\n","    agents = prey + pred\n","\n","    num_predators = len(pred)\n","    num_targets = len(prey)\n","    target_index = list(range(0, num_targets))\n","    num_agents = num_predators + num_targets\n","\n","    p_target = 1\n","    target_boundary = (50, 50)\n","\n","    # Create env\n","    prng = np.random.RandomState(seed_value)\n","    env = CompetitiveGrid(num_agents=num_agents)\n","    targets = uniform_targets(num_targets, target_boundary, prng=prng)\n","    values = constant_values(targets, 1.0)\n","\n","    # Intial targets\n","    env.add_targets(\n","        target_index,\n","        targets,\n","        values,\n","        detection_radius=detection_radius,\n","        p_target=p_target,\n","    )\n","\n","    # !\n","    comp_exp = multi_experiment(\n","        f\"base\",\n","        agents,\n","        env,\n","        num_steps=num_steps,\n","        num_experiments=num_experiments,\n","        seed=seed_value,\n","        split_state=False,\n","        dump=False\n","    )\n","\n","    experiments.append(comp_exp)\n","    model_codes.append(0)\n","\n","  return experiments, model_codes, num_agents, env\n","\n","experiments, model_codes, num_agents, env = run_experiments()"]},{"cell_type":"markdown","metadata":{"id":"8O3tKIMArjiH"},"source":["#### Plot the movement behavior of the agents (nothing to code here)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hIvLKC-1qYjm"},"outputs":[],"source":["plot_boundary = (40, 40)\n","for n in range(5):\n","  for c_i in range(len(conditions)):\n","      ax = None\n","      ax = plot_positions2d(\n","          select_exp(experiments[c_i], n),\n","          num_agents,\n","          boundary=plot_boundary,\n","          labels=[f\"Prey{n}\" for n in range(3)] + [\"Pred\"],\n","          colors=None,\n","          alpha=0.6,\n","          figsize=(3, 3),\n","      )\n","      ax.set_title(f'{conditions[c_i]}_run{n}')"]},{"cell_type":"markdown","metadata":{"id":"aKLUmsURrZUr"},"source":["#### Obtain the metrics for each condition (nothing to code here)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NyJBCLBCqa78"},"outputs":[],"source":["def plot_metrics():\n","  '''\n","  Plots predator deaths, prey deaths, and fitness under each condition\n","  '''\n","  # Est. death\n","  pred_scores = []\n","  prey_scores = []\n","  for i, result in zip(model_codes, experiments):\n","      pred_scores.append(num_death(result))\n","      prey_scores.append(np.sum(total_reward(result)))\n","\n","  # Est. fitness\n","  fitness = np.asarray(prey_scores) - np.asarray(pred_scores)\n","  fitness = fitness.tolist()\n","\n","  fig = plt.figure(figsize=(3, 3))\n","  plt.bar(conditions, pred_scores, color=\"black\", alpha=0.6)\n","  plt.ylabel(\"Pred death\")\n","  plt.xlabel(\"Condition\")\n","  plt.ylim(0, num_experiments)\n","  plt.tight_layout()\n","  sns.despine()\n","\n","  fig = plt.figure(figsize=(3, 3))\n","  plt.bar(conditions, prey_scores, color=\"black\", alpha=0.6)\n","  plt.ylabel(\"Prey deaths\")\n","  plt.xlabel(\"Condition\")\n","  plt.ylim(0, num_experiments)\n","  plt.tight_layout()\n","  sns.despine()\n","\n","  fig = plt.figure(figsize=(3, 3))\n","  plt.bar(conditions, fitness, color=\"black\", alpha=0.6)\n","  plt.ylabel(\"Fitness\")\n","  plt.xlabel(\"Condition\")\n","  plt.tight_layout()\n","  plt.ylim(-num_experiments, num_experiments)\n","  sns.despine()\n","\n","plot_metrics()"]},{"cell_type":"markdown","metadata":{"id":"wtONpdYKZ0Ka"},"source":["### Question 2.1.1 [8 pt]\n","\n","What were fitness scores and prey deaths for each condition? Which prey was the most successful and why? Which prey was least successful and why? Which prey was in the middle and why? Refer to the movement behavior and metric plots in justifying your answer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_8lRsN07Orz6"},"outputs":[],"source":["# Write your answer here, as a python comment\n"]},{"cell_type":"markdown","metadata":{"id":"H34GK6Jgd4NR"},"source":["### Question 2.1.2 [8 pt]\n","\n","The predator is of type GreedyPredatorGrid that moves towards the nearest prey at each time step. What is a different movement pattern from a predator that would likely change the relative survival ranking of the three prey types?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R34XOMbHdqOm"},"outputs":[],"source":["# Write your answer here, as a python comment\n"]},{"cell_type":"markdown","metadata":{"id":"rrGwx1_7_NQy"},"source":["### Question 2.1.3 [8 pt]\n","\n","How would you predict each prey type to perform if the prey and predator emitted a scent and the predator moved by moving along the positive prey scent gradient (towards the prey), and the predators moved along the negative predator scent gradient (away from the predator)? Assume the prey and predators emit the same radius and magnitude of scent, and agent parameters are the default ones defined above for all agents."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X1v2jhE-Buec"},"outputs":[],"source":["# Write your answer here, as a python comment\n"]},{"cell_type":"markdown","metadata":{"id":"C6ziBVVINQJ4"},"source":["---\n","## Part 2.2 - Introducing a new predator\n","\n","In part 2.2, you will experiment with how the prey would need to adapt if a superior predator is introduced into an environment."]},{"cell_type":"markdown","metadata":{"id":"NCukFxd6Xqmp"},"source":["#### Define a new super predator that has the parameters (minimally) changed from the default values such that the predator has fitness >= 20 for each prey [2 pt]."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iav9f-zdPAy6"},"outputs":[],"source":["# Predator default parameters. Minimally change them (can be more than one if desired) to cause the predator to to have >= 20 fitness for each prey.\n","\n","# CHANGE BELOW (MINIMALLY), then run this cell to check metrics\n","pred_step_size = 1 # predator step size\n","p_move = 0.9 # probability of moving at each time step\n","detection_radius =  1 # detection radius to kill prey\n","\n","pred = [\n","    GreedyPredatorGrid(\n","        step_size=pred_step_size,\n","        p_move=p_move,\n","    )\n","]\n","\n","experiments, model_codes, num_agents, env = run_experiments()\n","\n","plot_metrics()"]},{"cell_type":"markdown","metadata":{"id":"nIuNOC_9ZwO8"},"source":["### Question 2.2.1 [8 pt]\n","\n","What parameters did you change and why did alter the metrics? Refer to specific aspects of the predator's behavior and the metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-5kY9vDhZwPG"},"outputs":[],"source":["# Write your answer here, as a python comment\n"]},{"cell_type":"markdown","metadata":{"id":"1TRsBKYgZblB"},"source":["#### Mutation: define a change in one of the preys' variables (scale, min_length, step_size, p_freeze) such that it enables one of the prey types to survive the new super prey with predator fitness <= 0 for the changed prey. You should only change one parameter in one of the prey types. [2 pt]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0RfZ26MXWas"},"outputs":[],"source":["# Change only a single parameter here to reach fitness <=0 for one prey!\n","\n","# CHANGE SINGLE PARAMETER BELOW, then run cell to check metrics\n","# Fast\n","fast_scale = 5\n","fast_min_length = 15\n","fast_step_size = 15\n","\n","# Flight\n","flight_exp = 15\n","flight_step_size = 11\n","\n","# Freeze\n","p_freeze = 0.9\n","freeze_exp = 3\n","freeze_step_size = 8\n","\n","# Define the preys again (you can copy your code from 2.1)\n","preys = [\n","    [\n","    # Define 3 Fast Prey\n","    # YOUR CODE HERE\n","    ],\n","    [\n","    # Define 3 Flight Prey\n","    # YOUR CODE HERE\n","    ],\n","    [\n","    # Define 3 Freeze Prey\n","    # YOUR CODE HERE\n","    ]\n","]\n","\n","experiments, model_codes, num_agents, env = run_experiments()\n","\n","plot_metrics()"]},{"cell_type":"markdown","metadata":{"id":"O-ySYa4sa2IJ"},"source":["### Question 2.2.2 [8 pt]\n","\n","Which parameter did you change, and how did it enable the prey to survive the new super predator?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LQd6rJ8Ga2IT"},"outputs":[],"source":["# Write your answer here, as a python comment\n"]},{"cell_type":"markdown","metadata":{"id":"q6Ssm_OmYJc2"},"source":["**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n","> *Write Name(s) here*"]},{"cell_type":"markdown","metadata":{"id":"NBI6ndXmYRA7"},"source":["**DUE:** 5pm ET, Oct. 23, 2023. Email the link to the completed notebook on your Github repository to the TA and me via Canvas."]}],"metadata":{"colab":{"provenance":[{"file_id":"1t2zWXdWYVJWShfHgHwjF0YNNmUMMKA7q","timestamp":1696556542482},{"file_id":"11yj0oGey1-f6ppoleGjrHMx0xWeg1pMH","timestamp":1665750569230}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}